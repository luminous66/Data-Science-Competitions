{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trainrecord = pd.read_csv('/train.csv', header=None, names=['userId', 'movieId', 'rating'])\n",
    "testrecord = pd.read_csv('/test.csv', header=None, names=['userId', 'movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Inputs\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data viz\n",
    "from mlens.visualization import corr_X_y, corrmat\n",
    "\n",
    "# Model evaluation\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "\n",
    "# Ensemble\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 148\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainrecord.head()\n",
    "X = []\n",
    "Y = []\n",
    "for i, row in trainrecord.iterrows():\n",
    "    x = (row['userId'], row['movieId'])\n",
    "    Y.append(row['rating'])\n",
    "    X.append(x)\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb = XGBRegressor(n_jobs=1, random_state=SEED)\n",
    "ls = Lasso(alpha=1e-6, normalize=True)\n",
    "el = ElasticNet(alpha=1e-6, normalize=True)\n",
    "rf = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "base_learners = [\n",
    "    ('ls', ls), ('el', el), ('rf', rf), ('gb', gb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ls : 0.9124\n",
      " el : 0.9122\n",
      " rf : 0.9101\n",
      " gb : 0.8883\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "P = np.zeros((xtest.shape[0], len(base_learners)))\n",
    "P = pd.DataFrame(P, columns=[e for e, _ in base_learners])\n",
    "\n",
    "for est_name, est in base_learners:\n",
    "    est.fit(xtrain, ytrain)\n",
    "    p = est.predict(xtest)\n",
    "    P.loc[:, est_name] = p\n",
    "    print(\"%3s : %.4f\" % (est_name, sqrt(mean_absolute_error(ytest, p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAIZCAYAAACCgrriAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzRQAwAg0UwAAI/j/hyfeD/0UVo0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b426fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = corrmat(P.corr())\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dicts = {\n",
    "    'ls':\n",
    "    {'alpha': uniform(1e-6, 1e-5)},\n",
    "    'el':\n",
    "    {'alpha': uniform(1e-6, 1e-5),\n",
    "     'l1_ratio': uniform(0, 1)\n",
    "    },\n",
    "    'gb':\n",
    "    {'learning_rate': uniform(0.02, 0.04),\n",
    "     'colsample_bytree': uniform(0.55, 0.66),\n",
    "     'min_child_weight': randint(30, 60),\n",
    "     'max_depth': randint(3, 7),\n",
    "     'subsample': uniform(0.4, 0.2),\n",
    "     'n_estimators': randint(150, 200),\n",
    "     'colsample_bytree': uniform(0.6, 0.4),\n",
    "     'reg_lambda': uniform(1, 2),\n",
    "     'reg_alpha': uniform(1, 2),\n",
    "    },\n",
    "    'rf':\n",
    "    {'max_depth': randint(2, 5),\n",
    "     'min_samples_split': randint(5, 20),\n",
    "     'min_samples_leaf': randint(10, 20),\n",
    "     'n_estimators': randint(50, 100),\n",
    "     'max_features': uniform(0.6, 0.3)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "evl = Evaluator(\n",
    "    scorer,\n",
    "    cv=2,\n",
    "    random_state=SEED,\n",
    "    verbose=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job\n",
      "Preprocessing 2 preprocessing pipelines over 2 CV folds\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "Preprocessing done | 00:00:00\n",
      "Evaluating 8 models for 2 parameter draws over 2 preprocessing pipelines and 2 CV folds, totalling 32 fits\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    8.1s finished\n",
      "Evaluation    done | 00:00:08\n",
      "Job           done | 00:00:08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlens.model_selection.model_selection.Evaluator at 0x11342df28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl.fit(\n",
    "    xtrain, ytrain,\n",
    "    estimators=base_learners,\n",
    "    param_dicts=param_dicts,\n",
    "    preprocessing={'sc': [StandardScaler()], 'none': []},\n",
    "    n_iter=2  # bump this up to do a larger grid search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score-m</th>\n",
       "      <th>test_score-s</th>\n",
       "      <th>train_score-m</th>\n",
       "      <th>train_score-s</th>\n",
       "      <th>fit_time-m</th>\n",
       "      <th>fit_time-s</th>\n",
       "      <th>pred_time-m</th>\n",
       "      <th>pred_time-s</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none.el</th>\n",
       "      <td>-0.831304</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>-0.830968</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>{'alpha': 6.754058522312349e-06, 'l1_ratio': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none.gb</th>\n",
       "      <td>-0.786532</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>-0.772718</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>2.243716</td>\n",
       "      <td>0.020265</td>\n",
       "      <td>0.269248</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>{'learning_rate': 0.0430162340892494, 'colsamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none.ls</th>\n",
       "      <td>-0.832389</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.832047</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>{'alpha': 6.754058522312349e-06}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none.rf</th>\n",
       "      <td>-0.812146</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>-0.808525</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.985899</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>0.074325</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 8, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.el</th>\n",
       "      <td>-0.831304</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>-0.830968</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>{'alpha': 6.754058522312349e-06, 'l1_ratio': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.gb</th>\n",
       "      <td>-0.786491</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>-0.772733</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>1.993322</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>0.359846</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>{'learning_rate': 0.0430162340892494, 'colsamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.ls</th>\n",
       "      <td>-0.832389</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.832047</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>{'alpha': 6.754058522312349e-06}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc.rf</th>\n",
       "      <td>-0.812146</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>-0.808523</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>1.075177</td>\n",
       "      <td>0.045871</td>\n",
       "      <td>0.066675</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 8, 'min_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_score-m  test_score-s  train_score-m  train_score-s  fit_time-m  \\\n",
       "none.el     -0.831304      0.001624      -0.830968       0.003611    0.003865   \n",
       "none.gb     -0.786532      0.005006      -0.772718       0.006302    2.243716   \n",
       "none.ls     -0.832389      0.001673      -0.832047       0.003626    0.002397   \n",
       "none.rf     -0.812146      0.004862      -0.808525       0.004002    0.985899   \n",
       "sc.el       -0.831304      0.001624      -0.830968       0.003611    0.010035   \n",
       "sc.gb       -0.786491      0.005088      -0.772733       0.006283    1.993322   \n",
       "sc.ls       -0.832389      0.001673      -0.832047       0.003626    0.005824   \n",
       "sc.rf       -0.812146      0.004864      -0.808523       0.004002    1.075177   \n",
       "\n",
       "         fit_time-s  pred_time-m  pred_time-s  \\\n",
       "none.el    0.000026     0.001317     0.000373   \n",
       "none.gb    0.020265     0.269248     0.006755   \n",
       "none.ls    0.000427     0.000561     0.000013   \n",
       "none.rf    0.048487     0.074325     0.000262   \n",
       "sc.el      0.005532     0.000737     0.000057   \n",
       "sc.gb      0.022101     0.359846     0.027755   \n",
       "sc.ls      0.002260     0.000662     0.000067   \n",
       "sc.rf      0.045871     0.066675     0.003617   \n",
       "\n",
       "                                                    params  \n",
       "none.el  {'alpha': 6.754058522312349e-06, 'l1_ratio': 0...  \n",
       "none.gb  {'learning_rate': 0.0430162340892494, 'colsamp...  \n",
       "none.ls                   {'alpha': 6.754058522312349e-06}  \n",
       "none.rf  {'max_depth': 4, 'min_samples_split': 8, 'min_...  \n",
       "sc.el    {'alpha': 6.754058522312349e-06, 'l1_ratio': 0...  \n",
       "sc.gb    {'learning_rate': 0.0430162340892494, 'colsamp...  \n",
       "sc.ls                     {'alpha': 6.754058522312349e-06}  \n",
       "sc.rf    {'max_depth': 4, 'min_samples_split': 8, 'min_...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evl.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.830162340892494,\n",
       " 'learning_rate': 0.0430162340892494,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 49,\n",
       " 'n_estimators': 169,\n",
       " 'reg_alpha': 2.1508117044624697,\n",
       " 'reg_lambda': 2.1508117044624697,\n",
       " 'subsample': 0.515081170446247}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl.results[\"params\"]['sc.gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for case_name, params in evl.results[\"params\"].items():\n",
    "    case, case_est = case_name.split('.')\n",
    "    for est_name, est in base_learners:\n",
    "        if est_name == case_est:\n",
    "            est.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will compare a GBM and an elastic net as the meta learner\n",
    "# These are cloned internally so we can go ahead and grab the fitted ones\n",
    "meta_learners = [\n",
    "    ('gb', gb), ('rf', rf)\n",
    "]\n",
    "\n",
    "# Note that when we have a preprocessing pipeline,\n",
    "# keys are in the (prep_name, est_name) format\n",
    "param_dicts = {\n",
    "    'rf':\n",
    "    {'max_depth': randint(2, 5),\n",
    "     'min_samples_split': randint(5, 20),\n",
    "     'min_samples_leaf': randint(10, 20),\n",
    "     'n_estimators': randint(50, 100),\n",
    "     'max_features': uniform(0.6, 0.3)\n",
    "    },\n",
    "    'gb':\n",
    "    {'learning_rate': uniform(0.01, 0.2),\n",
    "     'subsample': uniform(0.5, 0.5),\n",
    "     'reg_lambda': uniform(0.1, 1),\n",
    "     'n_estimators': randint(10, 100)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the layers you don't want to tune into an ensemble with model selection turned on\n",
    "# Just remember to turn it off when you're done!\n",
    "in_layer = SuperLearner(model_selection=True)\n",
    "in_layer.add(base_learners)\n",
    "\n",
    "preprocess = [in_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job\n",
      "Preprocessing 1 preprocessing pipelines over 2 CV folds\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "Preprocessing done | 00:00:04\n",
      "Evaluating 2 models for 10 parameter draws over 1 preprocessing pipelines and 2 CV folds, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.3min finished\n",
      "Evaluation    done | 00:01:17\n",
      "Job           done | 00:01:21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlens.model_selection.model_selection.Evaluator at 0x11342df28>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl.fit(\n",
    "    xtrain, ytrain,\n",
    "    meta_learners,\n",
    "    param_dicts,\n",
    "    preprocessing={'meta': preprocess},\n",
    "    n_iter=10                            # bump this up to do a larger grid search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score-m</th>\n",
       "      <th>test_score-s</th>\n",
       "      <th>train_score-m</th>\n",
       "      <th>train_score-s</th>\n",
       "      <th>fit_time-m</th>\n",
       "      <th>fit_time-s</th>\n",
       "      <th>pred_time-m</th>\n",
       "      <th>pred_time-s</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meta.gb</th>\n",
       "      <td>-0.790492</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>-0.761135</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>4.669716</td>\n",
       "      <td>0.077545</td>\n",
       "      <td>0.212733</td>\n",
       "      <td>0.116692</td>\n",
       "      <td>{'learning_rate': 0.12515078243898003, 'subsam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.rf</th>\n",
       "      <td>-0.787718</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>-0.787189</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>7.000429</td>\n",
       "      <td>0.099820</td>\n",
       "      <td>0.135358</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 6, 'min_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_score-m  test_score-s  train_score-m  train_score-s  fit_time-m  \\\n",
       "meta.gb     -0.790492      0.003870      -0.761135       0.008287    4.669716   \n",
       "meta.rf     -0.787718      0.003633      -0.787189       0.008167    7.000429   \n",
       "\n",
       "         fit_time-s  pred_time-m  pred_time-s  \\\n",
       "meta.gb    0.077545     0.212733     0.116692   \n",
       "meta.rf    0.099820     0.135358     0.015563   \n",
       "\n",
       "                                                    params  \n",
       "meta.gb  {'learning_rate': 0.12515078243898003, 'subsam...  \n",
       "meta.rf  {'max_depth': 4, 'min_samples_split': 6, 'min_...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evl.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=None, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...rer=None)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=None, sample_size=20, scorer=None, shuffle=False,\n",
       "       verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's pick the linear meta learner with the above tuned\n",
    "# hyper-parameters. Note that ideally, you'd want to tune\n",
    "# the ensemble as a whole, not each estimator at a time\n",
    "meta_learner = meta_learners[1][1]\n",
    "meta_learner.set_params(**evl.results[\"params\"][\"meta.rf\"])\n",
    "\n",
    "# We can grab the preprocessing layer and turn model selection off\n",
    "ens = in_layer\n",
    "ens.model_selection = False\n",
    "ens.add_meta(meta_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=2, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=None, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex...rer=None)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=None, sample_size=20, scorer=None, shuffle=False,\n",
       "       verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "pred = ens.predict(xtest)\n",
    "pred = np.round(xtest)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest, pred))\n",
    "\n",
    "print(\"ensemble score: %.4f\" % sqrt(mean_absolute_error(ytest, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "for i, row in testrecord.iterrows():\n",
    "    x = (row['userId'], row['movieId'])\n",
    "    Xtest.append(x)\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Xtest)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0966206 3.8180976 4.129749  3.927098  4.0967283 3.9169328 3.9169328\n",
      " 3.8988316 4.2452044 4.5055737 3.8988316 4.1335287 4.246747  4.1295705\n",
      " 4.0474887 3.4668722 3.8988316 3.8988316 4.4231787 4.2466955 3.885539\n",
      " 3.4668722 4.248605  4.148717  4.0966206 4.0966206 3.8988316 4.2452044\n",
      " 4.142849  3.927098  3.8402336 3.8432646 4.106792  3.8325562 4.1153836\n",
      " 3.7208478 3.8432646 4.1283455 4.115276  3.9100995 3.919994  3.9100995\n",
      " 3.6284122 3.5978372 3.5637228 3.6118476 3.705442  3.703935  4.0967283\n",
      " 3.8529475 3.6999109 3.8422434 3.8422434 3.5637228 3.5637228 3.5637228\n",
      " 3.5637228 3.5978372 3.5978372 3.5978372 3.8180976 3.8180976 3.8180976\n",
      " 4.122256  4.122256  4.122256  4.122256  3.6118476 3.8180976 3.8988316\n",
      " 3.8422434 3.8458488 3.8402336 4.0845776 3.8988316 3.9169328 3.8988316\n",
      " 3.5978372 3.906111  4.0811567 3.8988316 3.8988316 3.8988316 3.5978372\n",
      " 3.473227  3.8259125 3.8259125 3.2866232 4.122256  3.8988316 4.1372733\n",
      " 4.1372733 4.1372733 3.5978372 3.8180976 4.0966206 4.115276  4.0966206\n",
      " 4.0966206 4.0966206]\n"
     ]
    }
   ],
   "source": [
    "ens.fit(X, Y)\n",
    "pred = ens.predict(Xtest)\n",
    "print(pred[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('predictions.dat', pred, delimiter=\" \", fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
